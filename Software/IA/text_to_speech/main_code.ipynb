{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tjlm5wfT-ecO"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "executionInfo": {
     "elapsed": 671,
     "status": "error",
     "timestamp": 1731626416995,
     "user": {
      "displayName": "Sara Meriem Abdelhafid",
      "userId": "05964750610926943064"
     },
     "user_tz": -60
    },
    "id": "09i7bJfl-ecR",
    "outputId": "b1b61142-2a2f-4c6b-8f24-fa4d18dcc411"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import wave\n",
    "import pygame # type: ignore\n",
    "import langid # type: ignore\n",
    "#import openai\n",
    "#import librosa\n",
    "import sklearn # type: ignore\n",
    "import pyaudio # type: ignore #python bindings for PortAudio the cross_platform audio i/o  library\n",
    "# Load the pre-trained language identification model\n",
    "import fasttext # type: ignore # i sould use python 3.12.x verion it wont work with newer\n",
    "import playsound # type: ignore\n",
    "from gtts import gTTS # type: ignore\n",
    "import librosa.display # type: ignore\n",
    "from langdetect import detect # type: ignore\n",
    "from pydub import AudioSegment # type: ignore\n",
    "import pyttsx3 # type: ignore #text to speech\n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "import speech_recognition as sr # type: ignore #Speech to text\n",
    "from translate import Translator # type: ignore\n",
    "#from googletrans import Translator\n",
    "from tempfile import NamedTemporaryFile\n",
    "from IPython.display import Audio, display # type: ignore\n",
    "from transformers import MarianMTModel, MarianTokenizer # type: ignore\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer # type: ignore\n",
    "#from transliterate import translit\n",
    "# Ensure pydub can find the ffmpeg/ffprobe binary\n",
    "AudioSegment.converter = \"ffmpeg\"  # path to ffmpeg binary\n",
    "\n",
    "\n",
    "c=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npip install langid\\npip install scikit-learn\\npip install fasttext-wheel\\npip install playsound==1.2.2\\npip install librosa\\npip install matplotlib\\npip install langdetect\\npip install pydub\\npip install pyttsx3\\npip install pyttsx4\\npip install SpeechRecognition\\npip install speechrecognition\\npip install translate\\npip install transformers\\npip uninstall pyaudio\\npip install pyaudio\\npip install pydub simpleaudio\\npip install pygame\\npip install playsound\\nfrom tempfile import NamedTemporaryFile\\n\\n\\n#wget https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin\\n\\n\\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\\nbrew install ffmpeg\\nffmpeg -version\\n#brew install portaudio\\n'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "#…or create a new repository on the command line\n",
    "\n",
    "\n",
    "echo \"# Speechy_windows\" >> README.md\n",
    "git init\n",
    "git add README.md\n",
    "git commit -m \"first commit\"\n",
    "git branch -M main\n",
    "git remote add origin https://github.com/Sara-Meriem-Abdelhafid/Speechy_windows.git\n",
    "git remote set-url origin https://github.com/Sara-Meriem-Abdelhafid/Speechy_windows.git\n",
    "\n",
    "git remote -v\n",
    "git remote remove origin\n",
    "git push -u origin main\n",
    "\n",
    "Remove-Item -Recurse -Force .git\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pip install langid\n",
    "pip install scikit-learn\n",
    "pip install fasttext-wheel\n",
    "pip install playsound==1.2.2\n",
    "pip install librosa\n",
    "pip install matplotlib\n",
    "pip install langdetect\n",
    "pip install pydub\n",
    "pip install pyttsx3\n",
    "pip install pyttsx4\n",
    "pip install SpeechRecognition\n",
    "pip install speechrecognition\n",
    "pip install translate\n",
    "pip install transformers\n",
    "pip uninstall pyaudio\n",
    "pip install pyaudio\n",
    "pip install pydub simpleaudio\n",
    "pip install pygame\n",
    "pip install playsound\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pip install langid, scikit-learn, fasttext-wheel, playsound==1.2.2, librosa, matplotlib, langdetect, pydub, pyttsx3, pyttsx4, SpeechRecognition, speechrecognition, translate, transformers, pyaudio, pydub, simpleaudio, pygame, playsound\n",
    "pip uninstall pyaudio\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#wget https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin\n",
    "\n",
    "\n",
    "/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n",
    "brew install ffmpeg\n",
    "ffmpeg -version\n",
    "#brew install portaudio\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "arecord -l\n",
    "\n",
    "nano ~/.asoundrc\n",
    "\n",
    "pcm.capture {\n",
    "    type plug\n",
    "    slave {\n",
    "        pcm \"hw:3,0\"\n",
    "        rate 16000\n",
    "        format S16_LE\n",
    "        channels 1\n",
    "    }\n",
    "}\n",
    "\n",
    "sudo nano /etc/asound.conf\n",
    "pcm.!default {\n",
    "    type plug\n",
    "    slave.pcm \"plughw:3,0\"\n",
    "}\n",
    "\n",
    "\n",
    "git branch\n",
    "git status\n",
    "git remote -v ##Verify the Changes\n",
    "git remote -v\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#…or create a new repository on the command line\n",
    "\n",
    "echo \"# Speechy_windows\" >> README.md\n",
    "git init\n",
    "git add README.md\n",
    "git commit -m \"first commit\"\n",
    "git branch -M main\n",
    "git remote add origin https://github.com/Sara-Meriem-Abdelhafid/Speechy_windows.git\n",
    "git push -u origin main\n",
    "\n",
    "#…or push an existing repository from the command line\n",
    "\n",
    "git remote add origin https://github.com/Sara-Meriem-Abdelhafid/Speechy_windows.git\n",
    "git branch -M main\n",
    "git push -u origin main\n",
    "\n",
    "\n",
    "#If the origin remote is incorrect or outdated, you can update it:\n",
    "git remote set-url origin https://github.com/Sara-Meriem-Abdelhafid/Speechy_windows.git\n",
    "\n",
    "\n",
    "#If you want to completely reset the origin, remove it and then add it again:\n",
    "git remote remove origin\n",
    "\n",
    "git remote add origin https://github.com/Sara-Meriem-Abdelhafid/Speechy_windows.git\n",
    "\n",
    "\n",
    "#Verify the Changes\n",
    "git remote -v\n",
    "\n",
    "#Large Files: If you have files larger than 100MB, Git will reject them. Use Git LFS for large files.\n",
    "git lfs install\n",
    "git lfs track \"*.largefileextension\"\n",
    "git init\n",
    "git add .\n",
    "git commit -m \"Initial commit with folders\"\n",
    "git remote add origin https://github.com/Sara-Meriem-Abdelhafid/Speechy_windows.git\n",
    "git push -u origin main\n",
    "git push -u origin master\n",
    "\n",
    "git rm -r --cached Software/IA/text_to_speech/fastText\n",
    "git commit -m \"Update .gitignore and stop tracking fastText folder\"\n",
    "git check-ignore -v Software/IA/text_to_speech/fastText\n",
    "\n",
    "#Correct Command in PowerShell\n",
    "Get-ChildItem -Force\n",
    "Get-ChildItem -Force | Where-Object { $_.Name -eq '.gitignore' }\n",
    "\n",
    "\n",
    "\n",
    "#warning: in the working copy of 'Software/IA/text_to_speech/text_in_out/speech_to_text_output_file.txt', LF will be replaced by CRLF the next time Git touches it\n",
    "'''\n",
    "The warning you’re seeing is related to line endings in text files, which can differ between operating systems:\n",
    "\n",
    "LF (Line Feed): Used by Unix-based systems like Linux and macOS.\n",
    "CRLF (Carriage Return + Line Feed): Used by Windows.\n",
    "Git automatically handles line-ending conversions when files are checked out or committed to ensure compatibility across different platforms.\n",
    "'''\n",
    "\n",
    "\n",
    "git commit -m \"Update Note_book.txt\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eryjkqwV-ecT"
   },
   "source": [
    "## Used Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "wyLuLnJo-ecT",
    "outputId": "aaa5845a-6669-4cb2-d52a-5380cfe0c237"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#play audio function\\ndef play_audio(audio):\\n    audio_data = audio.get_wav_data()\\n    with wave.open(\"temp_audio.wav\", \"wb\") as f:\\n        f.setnchannels(1)\\n        f.setsampwidth(pyaudio.PyAudio().get_sample_size(pyaudio.paInt16))\\n        f.setframerate(16000)\\n        f.writeframes(audio_data)\\n\\n    # Open the temporary WAV file and play it\\n    p = pyaudio.PyAudio()\\n    wf = wave.open(\"temp_audio.wav\", \"rb\")# read byte mode\\n    stream = p.open(format=p.get_format_from_width(wf.getsampwidth()),\\n                    channels=wf.getnchannels(),\\n                    rate=wf.getframerate(),\\n                    output=True)\\n    data = wf.readframes(1024)\\n    while data:\\n        stream.write(data)\\n        data = wf.readframes(1024)\\n    stream.stop_stream()\\n    stream.close()\\n\\n    p.terminate()'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose_microphone\n",
    "def choose_microphone():\n",
    "    print(\"Available Microphones:\")\n",
    "    microphones = sr.Microphone.list_microphone_names()\n",
    "    for i, mic in enumerate(microphones):\n",
    "        print(f\"{i}: {mic}\")\n",
    "    while True:\n",
    "        choice = input(\"Enter the index or name of the microphone you want to use to record audio: \")\n",
    "        if choice.isdigit():\n",
    "            choice = int(choice)\n",
    "            if 0 <= choice < len(microphones):\n",
    "                print(f\"The microphone used is {choice} : {microphones[choice]}.\")\n",
    "                return choice\n",
    "        elif choice in microphones:\n",
    "            print(f\"The microphone used is {choice} : {microphones[choice]}.\")\n",
    "            return choice\n",
    "        print(\"Invalid choice. Please enter a valid index or microphone name.\")\n",
    "\n",
    "\n",
    "# Function to translate \"I'm Listening to you...\" automatically\n",
    "def translit_message(text,language):\n",
    "    translator = Translator(to_lang=language)\n",
    "\n",
    "    try:\n",
    "        # Translate using translate library\n",
    "        translation = translator.translate(text)\n",
    "        return translation\n",
    "    except Exception as e:\n",
    "        return f\"Language not supported for translation: {str(e)}\"\n",
    "\n",
    "\n",
    "# save input audio wave\n",
    "def save_input_audio(audio, c, save_dir=\"audio_in_out/inputs_audio\"):\n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    # Write wave file\n",
    "    sample_rate = 48000.0  # Hertz\n",
    "    frames = audio.get_wav_data()\n",
    "    wav_filename = os.path.join(save_dir, f\"input_audio_{c}.wav\")\n",
    "    with wave.open(wav_filename, 'w') as obj:\n",
    "        obj.setnchannels(1)  # Mono or 2\n",
    "        obj.setsampwidth(2)\n",
    "        obj.setframerate(sample_rate)\n",
    "        obj.writeframes(frames)\n",
    "\n",
    "    print(f\"Audio has been saved to: {wav_filename}\")\n",
    "    return wav_filename\n",
    "\n",
    "\n",
    "# save output audio wave\n",
    "def save_output_audio(audio, c, save_dir=\"audio_in_out/outputs_audio\"):\n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    # Write wave file\n",
    "    sample_rate = 48000.0  # Hertz\n",
    "    frames = audio.get_wav_data()\n",
    "    wav_filename = os.path.join(save_dir, f\"output_audio_{c}.wav\")\n",
    "    with wave.open(wav_filename, 'w') as obj:\n",
    "        obj.setnchannels(1)  # Mono or 2\n",
    "        obj.setsampwidth(2)\n",
    "        obj.setframerate(sample_rate)\n",
    "        obj.writeframes(frames)\n",
    "\n",
    "    print(f\"Audio has been saved to: {wav_filename}\")\n",
    "    return wav_filename\n",
    "\n",
    "\n",
    "# save the INPUT text output in a file\n",
    "def input_text_to_file(text, c, save_dir=\"text_in_out/inputs_text\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)  # Ensure the directory exists\n",
    "    file_path = os.path.join(save_dir, f\"input_text_{c}.txt\") \n",
    "    with open(file_path, \"a\", encoding=\"utf-8\") as f: #Specify utf-8 encoding\n",
    "        f.write(text + \"\\n\")\n",
    "        print(text,\" was written in \",file_path)\n",
    "\n",
    "\n",
    "# save the OUTPUT text output in a file\n",
    "def output_text_to_file(text, c, save_dir=\"text_in_out/outputs_text\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)  # Ensure the directory exists    # Added \n",
    "    file_path = os.path.join(save_dir, f\"output_text_{c}.txt\")\n",
    "    with open(file_path, \"a\", encoding=\"utf-8\") as f: # Specify utf-8 encoding  # Added encoding=\"utf-8\"\n",
    "        f.write(text + \"\\n\")\n",
    "        print(text,\" was written in \",file_path)\n",
    "\n",
    "\n",
    "# record Speech and convert it to Text as input\n",
    "def record_speech_to_text(chosen_microphone,c,language):\n",
    "    recognizer = sr.Recognizer()\n",
    "    #get audio and save it\n",
    "    with sr.Microphone(device_index=chosen_microphone) as source:\n",
    "        recognizer.adjust_for_ambient_noise(source)  # Adjust for noise\n",
    "        translation=translit_message(\"Hello I'm listening, how can I help you?\",language)\n",
    "        text_to_speech(translation, language)\n",
    "        print(translation,\"...\")\n",
    "        '''if language=='en' :\n",
    "            print(\"Listening...\")\n",
    "        elif language=='ar':\n",
    "            print(\"...في الاستماع\")\n",
    "        elif language=='fr':\n",
    "            print(\"écoute...\")'''\n",
    "        audio = recognizer.listen(source)\n",
    "        # Save the captured audio to a WAV file\n",
    "        wav_filename = save_input_audio(audio, c)\n",
    "\n",
    "        # Play back the captured audio\n",
    "        #play_audio(wav_filename)\n",
    "        \n",
    "\n",
    "\n",
    "    #convert audio to text\n",
    "    try:\n",
    "        # Use Google's speech recognition with language detection\n",
    "        text = recognizer.recognize_google(audio, language=language) # Use Google's speech recognition and Specify language parameter for Arabic ('ar')\n",
    "        print(\"audio has been converted to : \",text)\n",
    "        #input_text_to_file(text, c)\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Could not understand audio\")\n",
    "        return \"\"\n",
    "    except sr.RequestError as e:\n",
    "        print(\"Could not request results; {0}\".format(e))\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "# read the INPUT text from a file\n",
    "def read_text_from_inputs(c,save_dir=\"text_in_out/inputs_text\"):\n",
    "    file_path = os.path.join(save_dir, f\"input_text_{c}.txt\")\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "# read the OUTPUT text from a file\n",
    "def read_text_from_outputs(c,save_dir=\"text_in_out/outputs_text\"):\n",
    "    file_path = os.path.join(save_dir, f\"output_text_{c}.txt\")\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "# speak the text_output and save it in a file\n",
    "def text_to_speech(text, lang):\n",
    "    if not text.strip():  # If there is no text, return\n",
    "        translation = translit_message(\"There is no text_to_speech conversion.\", lang)\n",
    "        print(translation)\n",
    "        return  # Return if there is no text to convert\n",
    "\n",
    "    # Convert text to speech\n",
    "    with NamedTemporaryFile(delete=False, suffix=\".mp3\") as tmp_mp3:\n",
    "        tts = gTTS(text=text, lang=lang, slow=False)\n",
    "        tts.save(tmp_mp3.name)\n",
    "        tmp_mp3.flush()  # Ensure all data is written to the file\n",
    "\n",
    "        # Play the speech\n",
    "        #playsound.playsound(tmp_mp3.name, True)\n",
    "        play_audio(tmp_mp3)\n",
    "\n",
    "\n",
    "\n",
    "# speak the text_output and save it in a file\n",
    "def text_to_speach_input(text, lang, c, audio_save_dir=\"audio_in_out/inputs_audio\"):\n",
    "    if not text:\n",
    "        translation=translit_message(\"There is no text_to_speech conversion.\",lang)\n",
    "        print(translation)\n",
    "        return\n",
    "        '''if lang == 'en':\n",
    "            print(\"There is no text_to_speech conversion.\")\n",
    "        elif lang == 'ar':\n",
    "            print(\".لا يوجد نص للتحويل إلى كلام\")\n",
    "        elif lang == 'fr':\n",
    "            print(\"Il n’y a pas de conversion texte-parole.\")\n",
    "        '''\n",
    "\n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(audio_save_dir):\n",
    "        os.makedirs(audio_save_dir)\n",
    "\n",
    "    # Generate the filename for the wav file\n",
    "    wav_filename = os.path.join(audio_save_dir, f\"input_audio_{c}.wav\")\n",
    "\n",
    "    # Convert text to speech and save directly as wav using a temporary mp3 file\n",
    "    with NamedTemporaryFile(delete=True) as tmp_mp3:\n",
    "        tts = gTTS(text=text, lang=lang)\n",
    "        tts.save(tmp_mp3.name)\n",
    "\n",
    "        # Convert the mp3 file to wav\n",
    "        sound = AudioSegment.from_mp3(tmp_mp3.name)\n",
    "        sound.export(wav_filename, format=\"wav\")\n",
    "\n",
    "\n",
    "    # Play the wav file\n",
    "    playsound.playsound(wav_filename)\n",
    "\n",
    "    print(f\"The response audio has been saved to: {wav_filename}\")\n",
    "\n",
    "\n",
    "# speak the text_output and save it in a file\n",
    "def text_to_speach_output(text, lang, c, audio_save_dir=\"audio_in_out/outputs_audio\"):\n",
    "    if not text:\n",
    "        translation=translit_message(\"There is no text_to_speech conversion.\",lang)\n",
    "        print(translation)\n",
    "        return\n",
    "        '''if lang == 'en':\n",
    "            print(\"There is no text_to_speech conversion.\")\n",
    "        elif lang == 'ar':\n",
    "            print(\".لا يوجد نص للتحويل إلى كلام\")\n",
    "        elif lang == 'fr':\n",
    "            print(\"Il n’y a pas de conversion texte-parole.\")\n",
    "        '''\n",
    "\n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(audio_save_dir):\n",
    "        os.makedirs(audio_save_dir)\n",
    "\n",
    "    # Generate the filename for the wav file\n",
    "    wav_filename = os.path.join(audio_save_dir, f\"output_audio_{c}.wav\")\n",
    "\n",
    "    # Convert text to speech and save directly as wav using a temporary mp3 file\n",
    "    with NamedTemporaryFile(delete=True) as tmp_mp3:\n",
    "        tts = gTTS(text=text, lang=lang)\n",
    "        tts.save(tmp_mp3.name)\n",
    "\n",
    "        # Convert the mp3 file to wav\n",
    "        sound = AudioSegment.from_mp3(tmp_mp3.name)\n",
    "        sound.export(wav_filename, format=\"wav\")\n",
    "\n",
    "\n",
    "    # Play the wav file\n",
    "    playsound.playsound(wav_filename)\n",
    "\n",
    "    print(f\"The response audio has been saved to: {wav_filename}\")\n",
    "\n",
    "\n",
    "# speak the text_output from a file and save it in an audio\n",
    "def text_to_speach_output_from_file(c, audio_save_dir=\"audio_in_out/outputs_audio\"):\n",
    "    # Generate the filename for the wav file\n",
    "    wav_filename = os.path.join(audio_save_dir, f\"output_audio_{c}.wav\")\n",
    "\n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(audio_save_dir):\n",
    "        os.makedirs(audio_save_dir)\n",
    "\n",
    "    # Read the text from the file\n",
    "    text = read_text_from_outputs(c)\n",
    "    if not text:\n",
    "        #translation=translit_message(\"There is no text_to_speech conversion.\",language_code)\n",
    "        #print(translation)\n",
    "        print(\"There is no text_to_speech conversion.\")\n",
    "        '''if lang == 'en':\n",
    "            print(\"There is no text_to_speech conversion.\")\n",
    "        elif lang == 'ar':\n",
    "            print(\".لا يوجد نص للتحويل إلى كلام\")\n",
    "        elif lang == 'fr':\n",
    "            print(\"Il n’y a pas de conversion texte-parole.\")'''\n",
    "        return\n",
    "    language_code, language = detect_language(text)\n",
    "    print(\"text: \", text, \" in \",language)\n",
    "\n",
    "\n",
    "    # Convert text to speech and save directly as wav using a temporary mp3 file\n",
    "    with NamedTemporaryFile(delete=True) as tmp_mp3:\n",
    "        tts = gTTS(text=text,lang=language_code)#,\n",
    "        tts.save(tmp_mp3.name)\n",
    "\n",
    "        # Convert the mp3 file to wav\n",
    "        sound = AudioSegment.from_mp3(tmp_mp3.name)\n",
    "        sound.export(wav_filename, format=\"wav\")\n",
    "\n",
    "    # Play the wav file\n",
    "    playsound.playsound(wav_filename)\n",
    "\n",
    "    print(f\"The response audio has been saved to: {wav_filename}\")\n",
    "\n",
    "\n",
    "\n",
    "# Function to detect the language of the input text\n",
    "fasttext_model = fasttext.load_model('lid.176.bin')# Pre-Trained model for language identification\n",
    "# Language code to language name mapping\n",
    "language_mapping = {\n",
    "    \"af\": \"Afrikaans\",\n",
    "    \"ar\": \"Arabic\",\n",
    "    \"bg\": \"Bulgarian\",\n",
    "    \"bn\": \"Bengali\",\n",
    "    \"ca\": \"Catalan\",\n",
    "    \"cs\": \"Czech\",\n",
    "    \"da\": \"Danish\",\n",
    "    \"de\": \"German\",\n",
    "    \"el\": \"Greek\",\n",
    "    \"en\": \"English\",\n",
    "    \"es\": \"Spanish\",\n",
    "    \"et\": \"Estonian\",\n",
    "    \"fa\": \"Persian\",\n",
    "    \"fi\": \"Finnish\",\n",
    "    \"fr\": \"French\",\n",
    "    \"he\": \"Hebrew\",\n",
    "    \"hi\": \"Hindi\",\n",
    "    \"hr\": \"Croatian\",\n",
    "    \"hu\": \"Hungarian\",\n",
    "    \"id\": \"Indonesian\",\n",
    "    \"it\": \"Italian\",\n",
    "    \"ja\": \"Japanese\",\n",
    "    \"ka\": \"Georgian\",\n",
    "    \"ko\": \"Korean\",\n",
    "    \"lt\": \"Lithuanian\",\n",
    "    \"lv\": \"Latvian\",\n",
    "    \"mk\": \"Macedonian\",\n",
    "    \"ml\": \"Malayalam\",\n",
    "    \"mr\": \"Marathi\",\n",
    "    \"ms\": \"Malay\",\n",
    "    \"nl\": \"Dutch\",\n",
    "    \"no\": \"Norwegian\",\n",
    "    \"pl\": \"Polish\",\n",
    "    \"pt\": \"Portuguese\",\n",
    "    \"ro\": \"Romanian\",\n",
    "    \"ru\": \"Russian\",\n",
    "    \"sk\": \"Slovak\",\n",
    "    \"sl\": \"Slovenian\",\n",
    "    \"sq\": \"Albanian\",\n",
    "    \"sr\": \"Serbian\",\n",
    "    \"sv\": \"Swedish\",\n",
    "    \"sw\": \"Swahili\",\n",
    "    \"ta\": \"Tamil\",\n",
    "    \"te\": \"Telugu\",\n",
    "    \"th\": \"Thai\",\n",
    "    \"tl\": \"Tagalog\",\n",
    "    \"tr\": \"Turkish\",\n",
    "    \"uk\": \"Ukrainian\",\n",
    "    \"ur\": \"Urdu\",\n",
    "    \"vi\": \"Vietnamese\",\n",
    "    \"zh\": \"Chinese\",\n",
    "    # Add more languages as needed\n",
    "}\n",
    "# Function to detect the language of the input text using fastText\n",
    "def detect_language(text):\n",
    "    # Remove newline characters from the input text\n",
    "    text = text.replace('\\n', ' ')\n",
    "    predictions = fasttext_model.predict(text, k=1)  # k=1 returns the top prediction\n",
    "    language_code = predictions[0][0].replace('__label__', '')\n",
    "    language_name = language_mapping.get(language_code, \"Unknown\")\n",
    "    return language_code, language_name\n",
    "\n",
    "\n",
    "def play_audio(filename):\n",
    "    # Initialize the mixer\n",
    "    pygame.mixer.init()\n",
    "    pygame.mixer.music.load(filename)\n",
    "    pygame.mixer.music.play()\n",
    "    while pygame.mixer.music.get_busy():  # Wait until the sound finishes\n",
    "        pygame.time.Clock().tick(10)\n",
    "\n",
    "\n",
    "'''#play audio function\n",
    "def play_audio(audio):\n",
    "    audio_data = audio.get_wav_data()\n",
    "    with wave.open(\"temp_audio.wav\", \"wb\") as f:\n",
    "        f.setnchannels(1)\n",
    "        f.setsampwidth(pyaudio.PyAudio().get_sample_size(pyaudio.paInt16))\n",
    "        f.setframerate(16000)\n",
    "        f.writeframes(audio_data)\n",
    "\n",
    "    # Open the temporary WAV file and play it\n",
    "    p = pyaudio.PyAudio()\n",
    "    wf = wave.open(\"temp_audio.wav\", \"rb\")# read byte mode\n",
    "    stream = p.open(format=p.get_format_from_width(wf.getsampwidth()),\n",
    "                    channels=wf.getnchannels(),\n",
    "                    rate=wf.getframerate(),\n",
    "                    output=True)\n",
    "    data = wf.readframes(1024)\n",
    "    while data:\n",
    "        stream.write(data)\n",
    "        data = wf.readframes(1024)\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "\n",
    "    p.terminate()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b3pUUPSd-ecV"
   },
   "source": [
    "## Try Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "0MLm0Vv8-ecV",
    "outputId": "e6f8a244-aa87-4dc3-f2b8-5a14c1fea921"
   },
   "outputs": [],
   "source": [
    "# choose_microphone\n",
    "chosen_microphone = 1 #choose_microphone()#1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "YsWj6kEm-ecV"
   },
   "outputs": [],
   "source": [
    "#'''# Example usage:\n",
    "text_to_speech(\"Hello, how are you?\", \"en\") \n",
    "text_to_speech(\"أنا أستمع إليك\", \"ar\")#'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "I45yXLa9-ecW",
    "outputId": "25a89dc4-0be9-49a1-cecf-942cfd623d67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # Function to translate \"I\\'m Listening to you...\" automatically\\ntext=\"how are you?\"\\nprint(translit_message(text,\\'ar\\'))  # Output: أنا أستمع إليك... (or similar in Arabic)\\nprint(translit_message(text,\\'en\\'))  # Output: I\\'m Listening to you...\\nprint(translit_message(text,\\'fr\\'))  # Output: Je vous écoute... (or similar in French)\\nprint(translit_message(text,\\'it\\'))  # Output: 我在听你... (or similar in Chinese)'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' # Function to translate \"I'm Listening to you...\" automatically\n",
    "text=\"how are you?\"\n",
    "print(translit_message(text,'ar'))  # Output: أنا أستمع إليك... (or similar in Arabic)\n",
    "print(translit_message(text,'en'))  # Output: I'm Listening to you...\n",
    "print(translit_message(text,'fr'))  # Output: Je vous écoute... (or similar in French)\n",
    "print(translit_message(text,'it'))  # Output: 我在听你... (or similar in Chinese)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "IGrgdpXP-ecW",
    "outputId": "9e5d74fb-2109-4ce1-dabb-47a9623c1a25"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# save the INPUT text output in a file\\ninput_text_to_file(\"كم الساعة الان؟\", 1)\\n\\n\\n# save the OUTPUT text output in a file\\noutput_text_to_file(\"الساعة الان الواحدة و النصف\", 1) #'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# save the INPUT text output in a file\n",
    "input_text_to_file(\"كم الساعة الان؟\", 1)\n",
    "\n",
    "\n",
    "# save the OUTPUT text output in a file\n",
    "output_text_to_file(\"الساعة الان الواحدة و النصف\", 1) #'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "kAlRg3j--ecW",
    "outputId": "4afacf92-b5e7-4afe-a0fd-ca31c2c6771c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "مرحبًا، أنا أستمع، كيف يمكنني مساعدتك ؟ ...\n",
      "Audio has been saved to: audio_in_out/inputs_audio\\input_audio_6.wav\n",
      "Could not understand audio\n",
      "text recorded:  \n"
     ]
    }
   ],
   "source": [
    "# record Speech and convert it to Text as input\n",
    "text = record_speech_to_text(chosen_microphone,6,'ar')\n",
    "print(\"text recorded: \",text)#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eoBxKza8-ecX",
    "outputId": "0c30c0b0-a498-41e7-d3f7-231c327ce999"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:  كم عدد ايام الاسبوع\n",
      "\n",
      "\n",
      "The response audio has been saved to: audio_in_out/outputs_audio/output_audio_13.wav\n"
     ]
    }
   ],
   "source": [
    "'''# read the INPUT text from a file\n",
    "input=read_text_from_inputs(0)\n",
    "print(\"input: \",input)\n",
    "\n",
    "# read the OUTPUT text from a file\n",
    "output=read_text_from_outputs(13)\n",
    "print(\"output: \",output)\n",
    "\n",
    "#language_code, language = detect_language(output) #get language of output\n",
    "#text_to_speach_output(output, language_code, c) # speak the text_output and save it in a file '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L-y3AuAO-ecX",
    "outputId": "7a1907f0-397c-42ce-be1f-81c84c918c17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Example usage\\nprompt1 = \"Cómo estás hoy\"\\nprompt2 = \"Bonjour Speechy\"\\nprompt3 = \"Hello Speechy how are you\"\\nprompt4 = \"مرحبا سبيشي\"\\n\\ncode1, name1 = detect_language(prompt1)\\ncode2, name2 = detect_language(prompt2)\\ncode3, name3 = detect_language(prompt3)\\ncode4, name4 = detect_language(prompt4)\\n\\nprint(f\"The detected language1 is: {code1} ({name1})\")\\nprint(f\"The detected language2 is: {code2} ({name2})\")\\nprint(f\"The detected language3 is: {code3} ({name3})\")\\nprint(f\"The detected language4 is: {code4} ({name4})\")'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''detected language\n",
    "prompt1 = \"Cómo estás hoy\"\n",
    "prompt2 = \"Bonjour Speechy\"\n",
    "prompt3 = \"Hello Speechy how are you\"\n",
    "prompt4 = \"مرحبا سبيشي\"\n",
    "\n",
    "code1, name1 = detect_language(prompt1)\n",
    "code2, name2 = detect_language(prompt2)\n",
    "code3, name3 = detect_language(prompt3)\n",
    "code4, name4 = detect_language(prompt4)\n",
    "\n",
    "print(f\"The detected language1 is: {code1} ({name1})\")\n",
    "print(f\"The detected language2 is: {code2} ({name2})\")\n",
    "print(f\"The detected language3 is: {code3} ({name3})\")\n",
    "print(f\"The detected language4 is: {code4} ({name4})\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GgFDidkM-ecX",
    "outputId": "014ba10c-83cf-4a4d-9879-609d651dbcb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "أهلًا، أنا منصت ...\n",
      "Audio has been saved to: audio_in_out/inputs_audio/input_audio_4.wav\n",
      "audio has been converted to :  شقد ديري\n",
      "text recorded:  شقد ديري\n",
      "شقد ديري  was written in  text_in_out/inputs_text/input_text_4.txt\n",
      "input:  شقد ديري  in  Arabic\n",
      "شقد ديري\n",
      "  was written in  text_in_out/outputs_text/output_text_4.txt\n",
      "text:  شقد ديري\n",
      "\n",
      "  in  Arabic\n",
      "The response audio has been saved to: audio_in_out/outputs_audio/output_audio_4.wav\n"
     ]
    }
   ],
   "source": [
    "# General Test\n",
    "c+=1\n",
    "\n",
    "#GET INPUT\n",
    "\n",
    "input_text = record_speech_to_text(chosen_microphone,c,'ar')# record Speech and convert it to Text as input\n",
    "print(\"text recorded: \",input_text)\n",
    "input_text_to_file(input_text, c) #save input to file in inputs_folder\n",
    "language_code, language = detect_language(input_text)\n",
    "print(\"input: \", input_text, \" in \",language)\n",
    "playsound.playsound(f\"audio_in_out/inputs_audio/input_audio_{c}.wav\")  # Play the input wav file in recorded voice instead of speak it\n",
    "#text_to_speach_input(input_text, language_code, c)\n",
    "\n",
    "\n",
    "\n",
    "#GENERATE OUTPUT\n",
    "gen_output=read_text_from_inputs(c) #geting text from inputs insted of generating a new output based on the input    #(in futer) generating a new output based on the input\n",
    "output_text_to_file(gen_output, c)  #save gen_output to a file in outputs_folder\n",
    "\n",
    "\n",
    "\n",
    "#GIVE OUTPUT\n",
    "#output=read_text_from_outputs(c)    #get output from outputs_folder\n",
    "#language_code, language = detect_language(output) #get language of output\n",
    "#text_to_speach_output(output, language_code, c) # speak the text_output and save it in a file\n",
    "text_to_speach_output_from_file(c)# speak the text_output from a file and save it in an audio '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WmwzbkgT-ecX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_5HbxlT--ecX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sCF79CRt-ecX"
   },
   "outputs": [],
   "source": [
    "'''plt.figure(figsize=(14, 5))\n",
    "librosa.display.waveshow(data, sr=sr)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ZtdCa-S-ecY"
   },
   "outputs": [],
   "source": [
    "# spectrogram\n",
    "'''X = librosa.stft(data) #short-time Fourier transform (STFT)\n",
    "Xdb = librosa.amplitude_to_db(abs(X))\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')\n",
    "plt.colorbar()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jLRvc3HC-ecY"
   },
   "outputs": [],
   "source": [
    "#Features Analysis, Spectral Centroid\n",
    "'''import sklearn.preprocessing\n",
    "\n",
    "\n",
    "spectral_centroids = librosa.feature.spectral_centroid(y=data, sr=sr)[0]\n",
    "print(spectral_centroids.shape)\n",
    "\n",
    "#computing the time variable for visualization\n",
    "plt.figure(figsize=(14,5))\n",
    "frames = range(len(spectral_centroids))\n",
    "t= librosa.frames_to_time(frames)\n",
    "\n",
    "#normalizing the spectral centroids for visualisation\n",
    "def normalize(x, axis=0):\n",
    "    return sklearn.preprocessing.minmax_scale(x, axis=0)\n",
    "#plotting the spectral centroids along the waveform\n",
    "librosa.display.waveshow(data, sr=sr, alpha=0.4)\n",
    "plt.plot(t, normalize(spectral_centroids), color='b')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nzzCEFhO-ecY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EZ7zA_p1-ecY"
   },
   "outputs": [],
   "source": [
    "'''import speech_recognition as sr\n",
    "\n",
    "def list_microphones():\n",
    "    for i, mic in enumerate(sr.Microphone.list_microphone_names()):\n",
    "        print(f\"{i}: {mic}\")\n",
    "\n",
    "def choose_microphone():\n",
    "    print(\"Please choose a microphone from the list:\")\n",
    "    list_microphones()\n",
    "    mic_index = int(input(\"Enter the microphone index: \"))\n",
    "    return mic_index\n",
    "\n",
    "def record_text(mic_index, recognizer):\n",
    "    with sr.Microphone(device_index=mic_index) as source:\n",
    "        print(\"Say something!\")\n",
    "        audio = recognizer.listen(source)\n",
    "    return audio\n",
    "\n",
    "def main():\n",
    "    recognizer = sr.Recognizer()\n",
    "    chosen_microphone = choose_microphone()\n",
    "\n",
    "    try:\n",
    "        audio = record_text(chosen_microphone, recognizer)\n",
    "        text = recognizer.recognize_google(audio, language='ar')\n",
    "        print(\"You said: \" + text)\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Google Speech Recognition could not understand audio\")\n",
    "    except sr.RequestError as e:\n",
    "        print(f\"Could not request results from Google Speech Recognition service; {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ivgEc9H-ecY"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lb1kEI5R-ecY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "us_GgCrq-ecY"
   },
   "source": [
    "## 1. Detect Language:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gdhSeQLk-ecY"
   },
   "outputs": [],
   "source": [
    "# Function to detect the language of the input text\n",
    "# Load the pre-trained fastText model for language identification\n",
    "fasttext_model = fasttext.load_model('lid.176.bin')# Pre-Trained model for language identification\n",
    "\n",
    "# Function to detect the language of the input text using fastText\n",
    "def detect_language(text):\n",
    "    predictions = fasttext_model.predict(text, k=1)  # k=1 returns the top prediction\n",
    "    language_code = predictions[0][0].replace('__label__', '')\n",
    "    return language_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mvaoa8rT-ecY"
   },
   "outputs": [],
   "source": [
    "'''prompt1 = \"Cómo estás hoy\"\n",
    "prompt2 = \"Bonjour Speechy\"\n",
    "prompt3 = \"Hello Speechy how are you\"\n",
    "prompt4 = \"مرحبا سبيشي\"\n",
    "\n",
    "print(f\"The detected language1 is: {detect_language(prompt1)}\")\n",
    "print(f\"The detected language2 is: {detect_language(prompt2)}\")\n",
    "print(f\"The detected language3 is: {detect_language(prompt3)}\")\n",
    "print(f\"The detected language4 is: {detect_language(prompt4)}\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zi4shFSk-ecZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Function to convert speech to text\n",
    "def speech_to_text(audio_file):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_file) as source:\n",
    "        audio = recognizer.record(source)\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio)\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        return \"\"\n",
    "    except sr.RequestError as e:\n",
    "        return \"\"\n",
    "\n",
    "# Function to record audio and save it to a file\n",
    "def record_audio(output_file, duration=5):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Recording audio...\")\n",
    "        audio = recognizer.listen(source, phrase_time_limit=duration)\n",
    "        with open(output_file, \"wb\") as f:\n",
    "            f.write(audio.get_wav_data())\n",
    "    print(f\"Audio recorded and saved as {output_file}\")\n",
    "\n",
    "# Record audio\n",
    "audio_file = \"recorded_audio.wav\"\n",
    "record_audio(audio_file)\n",
    "\n",
    "# Convert the recorded audio to text\n",
    "text = speech_to_text(audio_file)\n",
    "if text:\n",
    "    print(f\"Transcribed Text: {text}\")\n",
    "    # Detect the language of the transcribed text\n",
    "    language = detect_language(text)\n",
    "    print(f\"Detected Language: {language}\")\n",
    "else:\n",
    "    print(\"Could not transcribe the audio.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0DmEvfH_-ecZ"
   },
   "source": [
    "## 2. Generate Response:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UJnJZRSm-ecZ"
   },
   "outputs": [],
   "source": [
    "# Assuming we have a function `generate_response` that uses GPT-4\n",
    "'''# Function to generate a response using a multilingual model\n",
    "'' 'def generate_response(prompt, language):\n",
    "    # For simplicity, assume we're using a multilingual variant of GPT-4 or similar\n",
    "    # Load a pre-trained model and tokenizer\n",
    "    model_name = 'gpt-4-multilingual'\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    print(tokenizer)\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "    # Encode the input prompt\n",
    "    inputs = tokenizer.encode(prompt, return_tensors='pt')\n",
    "\n",
    "    # Generate a response\n",
    "    outputs = model.generate(inputs, max_length=100, num_return_sequences=1)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response'' '\n",
    "\n",
    "\n",
    "\n",
    "# Function to generate a response using a multilingual translation model\n",
    "def generate_response(prompt, language):\n",
    "    # Load the pre-trained model and tokenizer for translation\n",
    "    model_name = 'Helsinki-NLP/opus-mt-mul-en'\n",
    "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "    print(tokenizer)\n",
    "\n",
    "    ' ''model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "    # Translate prompt to English for processing\n",
    "    translated = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    translated_text = model.generate(translated)\n",
    "    translated_prompt = tokenizer.decode(translated_text[0], skip_special_tokens=True)\n",
    "\n",
    "    # Here you would use a GPT model to generate a response in English\n",
    "    # For simplicity, let's mock this step with a simple response\n",
    "    response_in_english = f\"This is a generated response for: {translated_prompt}\"\n",
    "\n",
    "    # Translate the response back to the original language\n",
    "    back_translated = tokenizer.encode(response_in_english, return_tensors='pt')\n",
    "    back_translated_text = model.generate(back_translated)\n",
    "    final_response = tokenizer.decode(back_translated_text[0], skip_special_tokens=True)\n",
    "\n",
    "    return final_response'' '\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "prompt = \"hello Speechy\"\n",
    "language = detect_language(prompt)\n",
    "print(f\"hello Speechy is in {language}\")\n",
    "\n",
    "generate_response(prompt, language)\n",
    "#response = generate_response(prompt, language)\n",
    "#print(response)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgs5l49m-ecZ"
   },
   "source": [
    "## 3. googletrans  Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r0qYdrgl-ecZ"
   },
   "outputs": [],
   "source": [
    "'''translator = Translator()\n",
    "\n",
    "# Translate prompt to English\n",
    "translated_prompt = translator.translate(prompt, src=language, dest='en').text\n",
    "\n",
    "# Generate response in English\n",
    "response_in_english = generate_response(translated_prompt)\n",
    "\n",
    "# Translate response back to the detected language\n",
    "final_response = translator.translate(response_in_english, src='en', dest=language).text\n",
    "print(final_response)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-tYAZ1PW-ecZ"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "import os\n",
    "import openai\n",
    "import langid\n",
    "from translate import Translator\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Function to detect the language of the input text using langid\n",
    "def detect_language(text):\n",
    "    lang, _ = langid.classify(text)\n",
    "    return lang\n",
    "\n",
    "# Function to translate text using the translate library\n",
    "def translate_text(text, from_lang, to_lang):\n",
    "    translator = Translator(from_lang=from_lang, to_lang=to_lang)\n",
    "    return translator.translate(text)\n",
    "\n",
    "# Function to generate a response using OpenAI's GPT-3/4\n",
    "def generate_response(prompt, language):\n",
    "    # Translate the prompt to English if it's not in English\n",
    "    if language != 'en':\n",
    "        prompt_in_english = translate_text(prompt, language, 'en')\n",
    "    else:\n",
    "        prompt_in_english = prompt\n",
    "\n",
    "    # Generate a response using OpenAI's GPT-3/4\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt_in_english,\n",
    "        max_tokens=150\n",
    "    )\n",
    "\n",
    "    response_in_english = response.choices[0].text.strip()\n",
    "\n",
    "    # Translate the response back to the original language if it's not in English\n",
    "    if language != 'en':\n",
    "        final_response = translate_text(response_in_english, 'en', language)\n",
    "    else:\n",
    "        final_response = response_in_english\n",
    "\n",
    "    return final_response\n",
    "\n",
    "# Example usage\n",
    "prompts = [\"Cómo estás hoy\", \"bonjour Speechy\", \"Hello Speechy how are you\", \"مرحبا سبيشي\"]\n",
    "for i, prompt in enumerate(prompts, 1):\n",
    "    language = detect_language(prompt)\n",
    "    print(f\"Detected language for prompt {i}: {language}\")\n",
    "    response = generate_response(prompt, language)\n",
    "    print(f\"Response {i}: {response}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ughffRY3-ecZ"
   },
   "outputs": [],
   "source": [
    "#### INPUT\n",
    "#select a microphone #chosen_microphone = choose_microphone()\n",
    "#get_input_audio 1\n",
    "#audio_to_text_input 1\n",
    "#save_text_to_file 1\n",
    "\n",
    "#### OUTPUT\n",
    "#generate_output_text 0\n",
    "#save_text_to_file 1\n",
    "#text_to_speech_autput 1\n",
    "#play_output 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SF9QHc9W-ecZ"
   },
   "outputs": [],
   "source": [
    "#play audio function\n",
    "def play_audio(audio):\n",
    "    audio_data = audio.get_wav_data()\n",
    "    with wave.open(\"temp_audio.wav\", \"wb\") as f:\n",
    "        f.setnchannels(1)\n",
    "        f.setsampwidth(pyaudio.PyAudio().get_sample_size(pyaudio.paInt16))\n",
    "        f.setframerate(16000)\n",
    "        f.writeframes(audio_data)\n",
    "\n",
    "    # Open the temporary WAV file and play it\n",
    "    p = pyaudio.PyAudio()\n",
    "    wf = wave.open(\"temp_audio.wav\", \"rb\")# read byte mode\n",
    "    stream = p.open(format=p.get_format_from_width(wf.getsampwidth()),\n",
    "                    channels=wf.getnchannels(),\n",
    "                    rate=wf.getframerate(),\n",
    "                    output=True)\n",
    "    data = wf.readframes(1024)\n",
    "    while data:\n",
    "        stream.write(data)\n",
    "        data = wf.readframes(1024)\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "\n",
    "    p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EUa1o4cc-eca"
   },
   "outputs": [],
   "source": [
    "# Load the pre-trained fastText model for language identification\n",
    "fasttext_model = fasttext.load_model('lid.176.bin')\n",
    "\n",
    "# Function to detect the language of the input text using fastText\n",
    "def detect_language(text):\n",
    "    predictions = fasttext_model.predict(text, k=1)  # k=1 returns the top prediction\n",
    "    language_code = predictions[0][0].replace('__label__', '')\n",
    "    return language_code\n",
    "\n",
    "# Function to convert speech to text\n",
    "def speech_to_text(audio_file):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_file) as source:\n",
    "        audio = recognizer.record(source)\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio)\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        return \"\"\n",
    "    except sr.RequestError as e:\n",
    "        return \"\"\n",
    "\n",
    "# Function to record audio and save it to a file\n",
    "def record_audio(output_file, duration=5):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Recording audio...\")\n",
    "        audio = recognizer.listen(source, phrase_time_limit=duration)\n",
    "        with open(output_file, \"wb\") as f:\n",
    "            f.write(audio.get_wav_data())\n",
    "    print(f\"Audio recorded and saved as {output_file}\")\n",
    "\n",
    "# Record audio\n",
    "audio_file = \"/recorded_audio.wav\"\n",
    "record_audio(audio_file)\n",
    "\n",
    "'''# Convert the recorded audio to text\n",
    "text = speech_to_text(audio_file)\n",
    "if text:\n",
    "    print(f\"Transcribed Text: {text}\")\n",
    "    # Detect the language of the transcribed text\n",
    "    language = detect_language(text)\n",
    "    print(f\"Detected Language: {language}\")\n",
    "else:\n",
    "    print(\"Could not transcribe the audio.\")'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-LtyLkJE-eca"
   },
   "outputs": [],
   "source": [
    "'''import os\n",
    "import fasttext\n",
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "from playsound import playsound\n",
    "from pydub import AudioSegment\n",
    "from tempfile import NamedTemporaryFile\n",
    "'''\n",
    "# Load the pre-trained fastText model for language identification\n",
    "fasttext_model = fasttext.load_model('lid.176.bin')\n",
    "\n",
    "# Function to detect the language of the input text using fastText\n",
    "def detect_language(text):\n",
    "    predictions = fasttext_model.predict(text, k=1)  # k=1 returns the top prediction\n",
    "    language_code = predictions[0][0].replace('__label__', '')\n",
    "    return language_code\n",
    "\n",
    "# Function to convert speech to text\n",
    "def speech_to_text(audio_file):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_file) as source:\n",
    "        audio = recognizer.record(source)\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio)\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        return \"\"\n",
    "    except sr.RequestError as e:\n",
    "        return \"\"\n",
    "\n",
    "# Function to record audio and save it to a file\n",
    "def record_audio(output_file, duration=5):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Recording audio...\")\n",
    "        audio = recognizer.listen(source, phrase_time_limit=duration)\n",
    "        with open(output_file, \"wb\") as f:\n",
    "            f.write(audio.get_wav_data())\n",
    "    print(f\"Audio recorded and saved as {output_file}\")\n",
    "\n",
    "# Function to save text to a file\n",
    "def save_text_to_file(text, filename):\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(text)\n",
    "\n",
    "# Function to read text from a specific paragraph in a file\n",
    "def read_paragraph_from_file(filename, paragraph_num):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        paragraphs = f.read().split(\"\\n\\n\")\n",
    "        if paragraph_num < len(paragraphs):\n",
    "            return paragraphs[paragraph_num]\n",
    "        else:\n",
    "            return \"\"\n",
    "\n",
    "# Function to convert text to speech and save it as a wav file\n",
    "def text_to_speech(text, lang, output_file):\n",
    "    with NamedTemporaryFile(delete=True) as tmp_mp3:\n",
    "        tts = gTTS(text=text, lang=lang)\n",
    "        tts.save(tmp_mp3.name)\n",
    "        sound = AudioSegment.from_mp3(tmp_mp3.name)\n",
    "        sound.export(output_file, format=\"wav\")\n",
    "\n",
    "# Function to play the audio file\n",
    "def play_audio(file):\n",
    "    playsound(file)\n",
    "\n",
    "# Main process\n",
    "def main():\n",
    "    input_audio_file = \"input_audio.wav\"\n",
    "    transcribed_text_file = \"transcribed_text.txt\"\n",
    "    output_text_file = \"output_text.txt\"\n",
    "    output_audio_file = \"output_audio.wav\"\n",
    "\n",
    "    # INPUT\n",
    "    # Record audio\n",
    "    record_audio(input_audio_file)\n",
    "\n",
    "    # Convert audio to text\n",
    "    transcribed_text = speech_to_text(input_audio_file)\n",
    "    print(f\"Transcribed Text: {transcribed_text}\")\n",
    "\n",
    "    # Save transcribed text to a file\n",
    "    save_text_to_file(transcribed_text, transcribed_text_file)\n",
    "\n",
    "    # OUTPUT\n",
    "    # Generate output text (for simplicity, we will use the same transcribed text)\n",
    "    output_text = transcribed_text\n",
    "\n",
    "    # Save output text to a file\n",
    "    save_text_to_file(output_text, output_text_file)\n",
    "\n",
    "    # Detect language of the output text\n",
    "    language = detect_language(output_text)\n",
    "    print(f\"Detected Language: {language}\")\n",
    "\n",
    "    # Convert text to speech and save it as a wav file\n",
    "    text_to_speech(output_text, language, output_audio_file)\n",
    "\n",
    "    # Play the output audio\n",
    "    play_audio(output_audio_file)\n",
    "    print(f\"The response audio has been saved to: {output_audio_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
